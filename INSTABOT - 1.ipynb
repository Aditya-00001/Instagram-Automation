{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c47c54",
   "metadata": {},
   "source": [
    "# INSTABOT PROJECT-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9acbd",
   "metadata": {},
   "source": [
    "Your friend has opened a new Food Blogging handle on Instagram and wants to get famous. He wants to follow a lot of people so that he can get noticed quickly but it is a tedious task so he asks you to help him. As you have just learned automation using Selenium, you decided to help him by creating an Instagram Bot.\n",
    "You need to create different functions for each task.\n",
    "### Note :\n",
    "Don’t forget to remove your Username and Password from the python notebook before submission.\n",
    "Replace your username and password by ‘SAMPLE USERNAME’ and ‘SAMPLE PASSWORD’ where you have used them in your code for logging in to instagram\n",
    "Upload your code file for submission of this project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e14fea2",
   "metadata": {},
   "source": [
    "### In the cases we haven't taken the account which are private as the follower can't be extracted and we have closed the follower list and following list by ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1a780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wdw\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup as bs \n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74061bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = wb.Chrome()\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4cc01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.instagram.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412fab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'SAMPLE USERNAME'\n",
    "password = 'SAMPLE PASSWORD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033cfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = wdw(driver,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec123d67",
   "metadata": {},
   "source": [
    "## PROBLEM - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85803174",
   "metadata": {},
   "source": [
    "Login to your Instagram Handle\n",
    "1. Submit with sample username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95440d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOG_IN(username,password):\n",
    "    try :\n",
    "#       locating username textbox and sending username to it \n",
    "        user = wait.until(EC.presence_of_element_located((By.NAME,'username')))\n",
    "        user.send_keys(username)\n",
    "#       locating pass textbox and sending the password\n",
    "        pw = driver.find_element(By.NAME,'password')\n",
    "        pw.send_keys(password)\n",
    "        #locating login button \n",
    "        button = wait.until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"loginForm\"]/div[1]/div[3]/button/div')))\n",
    "        button.submit()\n",
    "        #Save Your Login Info? : Not Now\n",
    "        pop = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'_ac8f')))\n",
    "        pop.click()\n",
    "        #turn on notification? : not now\n",
    "#         ntfn = wait.until(EC.presence_of_element_located((By.XPATH,'//div/button[@class = \"_a9-- _a9_1\"]')))\n",
    "#         ntfn.click()\n",
    "    except TE:\n",
    "        print(\"Something went wrong! Try Again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4126b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_IN(username,password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7693bd05",
   "metadata": {},
   "source": [
    "## PROBLEM - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92554f7a",
   "metadata": {},
   "source": [
    "Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”\n",
    "1. Note : Make sure to avoid printing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a91455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_button():\n",
    "    driver.find_element(By.LINK_TEXT,'Search').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5386c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(se):\n",
    "    try:\n",
    "        #clcicking on search button and sending text\n",
    "        search_button()\n",
    "        srch = wait.until(EC.presence_of_element_located((By.XPATH, '//input[contains(@class, \"x1lugfcp \")]')))\n",
    "        srch.send_keys(se)\n",
    "        #extracting all serched handle\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH,\"//div/span[@class = 'x1lliihq x1plvlek xryxfnj x1n2onr6 x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x1i0vuye xvs91rp x1s688f x5n08af x10wh9bi x1wdrske x8viiok x18hxmgj']\")))\n",
    "        handles = driver.find_elements(By.XPATH,'//div/span[@class = \"x1lliihq x1plvlek xryxfnj x1n2onr6 x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x1i0vuye xvs91rp x1s688f x5n08af x10wh9bi x1wdrske x8viiok x18hxmgj\"]')\n",
    "#         print(handles)\n",
    "        name = []\n",
    "        for i in handles:\n",
    "            if (i.text == '') or (i.text[0] == '#'):\n",
    "                pass\n",
    "            else:\n",
    "                name.append(i.text)\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        #clearing search bar\n",
    "        \n",
    "        driver.find_element(By.XPATH,'//div[@class = \"_aawn _9-lv\"]').click()        \n",
    "        \n",
    "        return name\n",
    "\n",
    "        \n",
    "    except TE:\n",
    "        print(\"No Search Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893afecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilsefoodie\n",
      "singapore.foodie\n",
      "germany.explores\n",
      "fooderati\n",
      "china.travels\n",
      "austria.explores\n",
      "food\n",
      "foodiechina888\n",
      "capetown.travel\n",
      "uk.explores\n",
      "thefoodmedic\n",
      "pinn_yang\n",
      "brussels.travel\n",
      "yourfoodlab\n",
      "therese.lum\n",
      "mexico.explores\n",
      "usa.explores\n",
      "maldives.explores\n",
      "insiderfood\n",
      "sgfoodagency\n",
      "madrid.explore\n",
      "food52\n",
      "foodie_incarnate\n",
      "greece.explores\n",
      "praguetravelers\n",
      "singapore.explores\n",
      "newzealand.travelers\n",
      "the_food_alchimist\n",
      "foodpharmer\n",
      "harrodsfood\n",
      "taipeitravels\n",
      "japan.explores\n",
      "switzerland.explores\n",
      "vietnamtravelers\n",
      "sibungbung\n",
      "hongkong.explore\n",
      "thefoodbabe\n",
      "ediblegarden\n",
      "foodirectory\n",
      "paris.explore\n",
      "bangkok.explore\n",
      "foodnetwork\n",
      "sydney.explores\n",
      "omuk_food\n",
      "canada.explores\n",
      "Food Junction Grand Pakuwon\n",
      "Food Wanderer x Lakbay Museo\n",
      "Suite Food Lounge\n",
      "london.travelers\n"
     ]
    }
   ],
   "source": [
    "for i in search(\"food\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83408134",
   "metadata": {},
   "source": [
    "## PROBLEM - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46be32",
   "metadata": {},
   "source": [
    "Searching and Opening a profile using \n",
    "1. Open profile of “So Delhi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22626f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_search_profile(s):\n",
    "    try:\n",
    "        #locatong search box bar and sending text \n",
    "        srch = wait.until(EC.presence_of_element_located((By.XPATH, '//input[contains(@class, \"x1lugfcp \")]')))\n",
    "        srch.send_keys(s)\n",
    "        #locating searched result\n",
    "        pro = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div/span[@class = 'x1lliihq x1plvlek xryxfnj x1n2onr6 x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x1i0vuye xvs91rp x1s688f x5n08af x10wh9bi x1wdrske x8viiok x18hxmgj']\")))\n",
    "#         print(len(pro))\n",
    "        #locating the given profile\n",
    "        for i in pro:\n",
    "            if i.text == s:\n",
    "                i.click()\n",
    "                break\n",
    "        time.sleep(3)        \n",
    "    except TE:\n",
    "        print(\"No Search Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "96f6ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_search_profile_instaName(s):\n",
    "    try:\n",
    "        #locatong search box bar and sending text \n",
    "        srch = wait.until(EC.presence_of_element_located((By.XPATH, '//input[contains(@class, \"x1lugfcp \")]')))\n",
    "        srch.send_keys(s)\n",
    "        time.sleep(2)\n",
    "        #locating searched result\n",
    "        pro = wait.until(EC.presence_of_element_located((By.XPATH,\"//div/span[@class = 'x1lliihq x1plvlek xryxfnj x1n2onr6 x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x1i0vuye xvs91rp x1s688f x5n08af x10wh9bi x1wdrske x8viiok x18hxmgj']\")))\n",
    "        pro.click()    \n",
    "    except TE:\n",
    "        print(\"No Search Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "467b5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button() #to be used if search button is closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4852154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_search_profile_instaName('So Delhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8a15e",
   "metadata": {},
   "source": [
    "## PROBLEM - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e9913",
   "metadata": {},
   "source": [
    "Follow/Unfollow given handle - \n",
    "1. Open the Instagram Handle of “So Delhi”\n",
    "2. Start following it. Print a message if you are already following\n",
    "3. After following, unfollow the instagram handle. Print a message if you have already unfollowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162f47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def follow():\n",
    "    try:\n",
    "        #locating follow button\n",
    "        btn = wait.until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"_aacl _aaco _aacw _aad6 _aade\"]')))\n",
    "        #checking for text\n",
    "        if btn.text == \"Follow\":\n",
    "            btn.click()\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            print(\"Already Following\")\n",
    "    except TE:\n",
    "        print(\"Something Went Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5221a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfollow():\n",
    "    try:\n",
    "        #locating unfollow button\n",
    "        btn = wait.until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"_aacl _aaco _aacw _aad6 _aade\"]')))\n",
    "        #checking for text\n",
    "        if btn.text != \"Follow\":\n",
    "            btn.click()\n",
    "            time.sleep(3)\n",
    "            #locating for unfollow button in the popup\n",
    "            pop_up = wait.until(EC.presence_of_all_elements_located((By.XPATH,'//div/span/span[@class = \"x1lliihq x193iq5w x6ikm8r x10wlt62 xlyipyv xuxw1ft\"]')))\n",
    "            for i in pop_up:\n",
    "                if i.text == 'Unfollow':\n",
    "                    i.click()\n",
    "                    break\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            print(\"Already Unfollowing\")\n",
    "    except TE:\n",
    "        print(\"Something Went Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "46f730e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4184c37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "open_search_profile('So Delhi')\n",
    "follow()\n",
    "unfollow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551b93a",
   "metadata": {},
   "source": [
    "## PROBLEM - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b1630",
   "metadata": {},
   "source": [
    "Like/Unlike posts\n",
    "1. Liking the top 30 posts of the ‘dilsefoodie'. Print message if you have already liked it.\n",
    "2. Unliking the top 30 posts of the ‘dilsefoodie’. Print message if you have already unliked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31aac65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a5eb93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_search_profile(\"dilsefoodie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "223001f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_like():\n",
    "    try:\n",
    "        #scrolling for locating post\n",
    "        driver.execute_script('window.scrollTo(0, 6000);')\n",
    "        time.sleep(3)\n",
    "        driver.execute_script('window.scrollTo(0, -6000);')\n",
    "        time.sleep(3)\n",
    "        #locating post\n",
    "        posts = driver.find_elements(By.CLASS_NAME,'_aagu')\n",
    "        for i in range(30):\n",
    "            time.sleep(5)\n",
    "            posts[i].click()\n",
    "            time.sleep(5)\n",
    "            #locating like button\n",
    "            like = wait.until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"x6s0dn4 x78zum5 xdt5ytf xl56j7k\"]/span')))\n",
    "            ch_lk = bs(like.get_attribute('innerHTML'),\"html.parser\").svg['aria-label']\n",
    "            sz = bs(like.get_attribute('innerHTML'),\"html.parser\").svg['width']\n",
    "                \n",
    "            if ch_lk == 'Like':\n",
    "                like.click()\n",
    "            else :\n",
    "                print('You have already LIKED Post Number :', i+1)\n",
    "            time.sleep(2)\n",
    "            #locating cross button for closing post   \n",
    "            close = driver.find_elements(By.XPATH,\"//div[@class = 'x6s0dn4 x78zum5 xdt5ytf xl56j7k']\")\n",
    "            for j in close:\n",
    "                cl = bs(j.get_attribute(\"innerHTML\"),\"html.parser\").svg['aria-label']\n",
    "                if cl == \"Close\":\n",
    "                    j.click()\n",
    "                    break\n",
    "            time.sleep(2)\n",
    "            \n",
    "    except TE :\n",
    "        print(\"Something Went Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ca0c41fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have already LIKED Post Number : 1\n",
      "You have already LIKED Post Number : 2\n",
      "You have already LIKED Post Number : 3\n",
      "You have already LIKED Post Number : 4\n",
      "You have already LIKED Post Number : 5\n",
      "You have already LIKED Post Number : 6\n",
      "You have already LIKED Post Number : 7\n",
      "You have already LIKED Post Number : 8\n",
      "You have already LIKED Post Number : 9\n",
      "You have already LIKED Post Number : 10\n",
      "You have already LIKED Post Number : 11\n",
      "You have already LIKED Post Number : 12\n",
      "You have already LIKED Post Number : 13\n",
      "You have already LIKED Post Number : 14\n",
      "You have already LIKED Post Number : 15\n",
      "You have already LIKED Post Number : 16\n",
      "You have already LIKED Post Number : 17\n",
      "You have already LIKED Post Number : 18\n",
      "You have already LIKED Post Number : 19\n",
      "You have already LIKED Post Number : 20\n",
      "You have already LIKED Post Number : 21\n",
      "You have already LIKED Post Number : 22\n",
      "You have already LIKED Post Number : 23\n",
      "You have already LIKED Post Number : 24\n"
     ]
    }
   ],
   "source": [
    "post_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fecdde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_unlike():\n",
    "    try:\n",
    "        #scrolling for locating post\n",
    "        driver.execute_script('window.scrollTo(0, 6000);')\n",
    "        time.sleep(3)\n",
    "        driver.execute_script('window.scrollTo(0, -6000);')\n",
    "        time.sleep(3)\n",
    "        #locating post\n",
    "        posts = driver.find_elements(By.CLASS_NAME,'_aagu')\n",
    "        for i in range(30):\n",
    "            time.sleep(5)\n",
    "            posts[i].click()\n",
    "            time.sleep(5)\n",
    "            #locating like button\n",
    "            like = wait.until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"x6s0dn4 x78zum5 xdt5ytf xl56j7k\"]/span')))\n",
    "            ch_lk = bs(like.get_attribute('innerHTML'),\"html.parser\").svg['aria-label']\n",
    "            sz = bs(like.get_attribute('innerHTML'),\"html.parser\").svg['width']\n",
    "                \n",
    "            if ch_lk == 'Unlike':\n",
    "                like.click()\n",
    "            else :\n",
    "                print('You have already LIKED Post Number :', i+1)\n",
    "            time.sleep(2)        \n",
    "            #locating cross button for closing post    \n",
    "            close = driver.find_elements(By.XPATH,\"//div[@class = 'x6s0dn4 x78zum5 xdt5ytf xl56j7k']\")\n",
    "            for j in close:\n",
    "                cl = bs(j.get_attribute(\"innerHTML\"),\"html.parser\").svg['aria-label']\n",
    "                if cl == \"Close\":\n",
    "                    j.click()\n",
    "                    break\n",
    "            time.sleep(2)\n",
    "            \n",
    "    except TE :\n",
    "        print(\"Something Went Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "27c422a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "post_unlike()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6dcdb",
   "metadata": {},
   "source": [
    "## PROBLEM - 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe561c",
   "metadata": {},
   "source": [
    "Extract list of followers\n",
    "1.Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’.\n",
    "2.Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3476de",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back() #to be used when wanted to return to the previous page or multiple click to reach the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d12a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_follower():\n",
    "    try:\n",
    "        #locating followers button and click on it\n",
    "        follower_btn = wait.until(EC.presence_of_element_located((By.XPATH,'//li/a[@class = \"x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz _alvs _a6hd\"]')))\n",
    "        follower_btn.click()\n",
    "        #locating list of follower in the frame\n",
    "        time.sleep(2)\n",
    "        frame = driver.find_element(By.XPATH,\"//div[@class = '_aano']\")\n",
    "        #scrolling for 500 user\n",
    "        for i in range(60):\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",frame)\n",
    "        time.sleep(5)\n",
    "        name = []\n",
    "        #Extracting users\n",
    "        followers = driver.find_elements(By.XPATH,'//span[@class = \"_aacl _aaco _aacw _aacx _aad7 _aade\"]')\n",
    "        for i in followers[:500]:\n",
    "            name.append(i.text.split('\\n')[0])\n",
    "        return name    \n",
    "    except TE:\n",
    "        print(\"Something Went Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "29699240",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button()\n",
    "open_search_profile(\"sodelhi\")\n",
    "li = extract_follower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "869d022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sadafendo\n",
      "2 its_girlcalled_aish\n",
      "3 ek_chidiya_anek_chidiya\n",
      "4 satindersaggu10\n",
      "5 incrediblebharat._\n",
      "6 reyaj068\n",
      "7 sindhusaji50\n",
      "8 21_rahulverma\n",
      "9 el.solo.ride\n",
      "10 the_gallary_mehandi_art\n",
      "11 dee_ssingh\n",
      "12 orientalgardennh8\n",
      "13 rachitajadaun\n",
      "14 aryanshaikh6523\n",
      "15 thepriyanshyadav\n",
      "16 vivijay3355\n",
      "17 rotit_jatav_king_3_315\n",
      "18 aakiibkhann\n",
      "19 _.abbhyyy\n",
      "20 howaboutvivek\n",
      "21 abhishekrai_33\n",
      "22 simplyanjal15\n",
      "23 komal_singh095\n",
      "24 nitabathla61\n",
      "25 rajat3596\n",
      "26 laduramregar\n",
      "27 nurislam35422023\n",
      "28 pooa404\n",
      "29 vnddesigns\n",
      "30 shin.ingstar704\n",
      "31 manssinainwal\n",
      "32 itsshefalisharma\n",
      "33 prachi9988\n",
      "34 _.p_u_r_i._\n",
      "35 maahii_ve_\n",
      "36 bibhaskumarrout\n",
      "37 aksharaa.30\n",
      "38 tejasvinasi\n",
      "39 poojakandelsingh\n",
      "40 shivgoescold\n",
      "41 musknxs\n",
      "42 anandchauhansingh\n",
      "43 ritikaatal_05\n",
      "44 arpitak_kapoor\n",
      "45 sshrutiisharmaa\n",
      "46 danishdanish7762\n",
      "47 okvidhi\n",
      "48 ahm_izana__\n",
      "49 yuvvxnr\n",
      "50 v._.arora\n",
      "51 _shree_\n",
      "52 rishabh_681992\n",
      "53 is.that.ishan\n",
      "54 perii.peri.fries\n",
      "55 ketu_jain\n",
      "56 _foodie_vibes_18\n",
      "57 luvleenamakeovers\n",
      "58 dr.singh_var55\n",
      "59 rj_rajat612\n",
      "60 pritv69\n",
      "61 shubham.sr4\n",
      "62 pragya.sharmaaa\n",
      "63 patiljambotkar\n",
      "64 deepesh_kr_\n",
      "65 diyaadutta\n",
      "66 ketanpahwa\n",
      "67 hehe.naush_\n",
      "68 armaankalra3\n",
      "69 danishh.arora\n",
      "70 _rebal.magar__\n",
      "71 pavnii_agrawal\n",
      "72 moiom_phom\n",
      "73 raaj.kumar.1293575\n",
      "74 meenu_teotia12\n",
      "75 sonikasingh595\n",
      "76 aasman_e_ishq\n",
      "77 akki_dhiman\n",
      "78 i_tanishashaw\n",
      "79 happy_soul1000000\n",
      "80 riewyaa\n",
      "81 roopakshii_15\n",
      "82 _reverb_0325\n",
      "83 meerac_life\n",
      "84 shikhaswaraj2\n",
      "85 hj_urbane.pahadi\n",
      "86 humma_khuram\n",
      "87 rishikachoudhary_13\n",
      "88 prachichauhan148\n",
      "89 imvibhorr\n",
      "90 ektababbarmalik\n",
      "91 nishta_nanda\n",
      "92 brewinglifewithcoffee\n",
      "93 munazza4592\n",
      "94 manish_balhara22\n",
      "95 barkha_pahwa\n",
      "96 nadeemsiddiqui0120\n",
      "97 tejender_gahlaut\n",
      "98 food.islif\n",
      "99 neha.chandra.718\n",
      "100 ahsanmohammad1042\n",
      "101 rogerdsouza100\n",
      "102 swati21106\n",
      "103 meharsheel\n",
      "104 tanishkakharwal\n",
      "105 surendrabisht007\n",
      "106 yash_chaudry1\n",
      "107 adityas04\n",
      "108 divyam.s05\n",
      "109 neha6242\n",
      "110 raghugoyal12\n",
      "111 sonali111698\n",
      "112 su_mmer9706\n",
      "113 lost_soul_ank\n",
      "114 top05atg\n",
      "115 farmtrac218\n",
      "116 kapoormovies05\n",
      "117 uzmanaaz556\n",
      "118 aurorainthesky09\n",
      "119 purvapatil15\n",
      "120 preetibansal_23\n",
      "121 shreyans_h39\n",
      "122 amitsharma5962\n",
      "123 kittykillz03\n",
      "124 riddhima__jain\n",
      "125 furnitureruchi\n",
      "126 pr.ocrust\n",
      "127 _ehasas_e_zindagi_\n",
      "128 seeking_rumi\n",
      "129 chicscholarpriti\n",
      "130 komal_chaudhary_28\n",
      "131 manishkumar87\n",
      "132 sanchittm\n",
      "133 heyy._.priii\n",
      "134 abhi_rajjj\n",
      "135 faaizhussaini9\n",
      "136 prabhatmishra.xzy\n",
      "137 00_kalamkaar_00\n",
      "138 shoryagoel\n",
      "139 suripavneet\n",
      "140 dn.ya11\n",
      "141 suchiitaaa_\n",
      "142 shanjree\n",
      "143 nisha_sharma.9860\n",
      "144 raj_ayushi\n",
      "145 kunj._.pvtt_\n",
      "146 kun.ti123459196\n",
      "147 kira.nsingh7713\n",
      "148 uknishchay\n",
      "149 kritin.khanna\n",
      "150 soulfultouch69\n",
      "151 gunjanrathore._\n",
      "152 latakumar403\n",
      "153 anadhika_09\n",
      "154 viralsaiyan\n",
      "155 ssuresh.durai.karur\n",
      "156 its_irfan____\n",
      "157 sohailejaz9\n",
      "158 jxs0_0\n",
      "159 ___harshittt_\n",
      "160 naveenverma___\n",
      "161 jubarsan\n",
      "162 trishamoony\n",
      "163 naveendungarwal\n",
      "164 kawalchadha\n",
      "165 gurnoor_sehgalll\n",
      "166 oyeuttu_\n",
      "167 bhavnayadav8055\n",
      "168 snickersnee08\n",
      "169 shubham1478gupta\n",
      "170 soumya_core\n",
      "171 pulkitmittal08\n",
      "172 vivek_patel_001\n",
      "173 annonymous.019\n",
      "174 renuka._0923\n",
      "175 mohd____fahad00097\n",
      "176 s_a_m_i_x_a__\n",
      "177 dr.tarannumnaaz\n",
      "178 conqueror_am\n",
      "179 riturajsingh_20\n",
      "180 pintu9973419451\n",
      "181 duggal_2301\n",
      "182 _saloniiiiiiiiii._\n",
      "183 vandana.b.agarwal\n",
      "184 manika._.0115\n",
      "185 sho_pmyoutfits\n",
      "186 _mehulgoel_\n",
      "187 homedecor_kitchen1\n",
      "188 priyanka_foodblogerrr\n",
      "189 oshika397\n",
      "190 depak007dk\n",
      "191 anshdahiyaa\n",
      "192 its_ak_0018\n",
      "193 __s.u.n.s.h.i.n.e.__0\n",
      "194 bangathegreat08\n",
      "195 chaibrary\n",
      "196 rokaiya_khanam\n",
      "197 krxder\n",
      "198 ___snapshots_01\n",
      "199 aaarch21\n",
      "200 pr061188\n",
      "201 _srishtikanojia\n",
      "202 _saurabbhmehta_\n",
      "203 9693hibas\n",
      "204 pallabi_2097\n",
      "205 selin_on_a_journey\n",
      "206 nandani_thapa_\n",
      "207 laksh.dubey\n",
      "208 _meraki_023\n",
      "209 jes.ssica_\n",
      "210 tejaswini._14\n",
      "211 dibakar.pd\n",
      "212 07bhupen\n",
      "213 aman_myself\n",
      "214 vinusssssssssssss_s\n",
      "215 yorn_fury\n",
      "216 kanishka___1210\n",
      "217 shvetabudhraja\n",
      "218 kavay883\n",
      "219 delhi_call_boy_ncr_5\n",
      "220 mahimaaaaa_13\n",
      "221 alikhanabsar\n",
      "222 shadab_joneal\n",
      "223 raj_vishal_007\n",
      "224 yoha.nn94\n",
      "225 alpikagarg\n",
      "226 ____ankita_1117___\n",
      "227 mahak_pathak2002\n",
      "228 sumitchand21\n",
      "229 syedperwaizahmad\n",
      "230 vivek.porwal1\n",
      "231 believer.002\n",
      "232 sparrowhousebir\n",
      "233 vishal_.giri\n",
      "234 satabdi.pal\n",
      "235 beautiful_homez_\n",
      "236 thelegallyexhaustedmom\n",
      "237 varsha_jhala\n",
      "238 10yadavji28\n",
      "239 dipenkar\n",
      "240 adewwahyu\n",
      "241 satirical.chauhan\n",
      "242 snickers_801\n",
      "243 chavala.rajesh\n",
      "244 _vyom.s_\n",
      "245 mo704ali\n",
      "246 thecasualeditblog\n",
      "247 shobhitbhatnagar15\n",
      "248 a_bite_of_yummie\n",
      "249 aman.gupta.93\n",
      "250 muks__2811\n",
      "251 offical_jaani770\n",
      "252 aviral_ahirwar\n",
      "253 delhii_foodies\n",
      "254 koli033\n",
      "255 maalabites\n",
      "256 abhiraj.singh09\n",
      "257 alwayz_sukan\n",
      "258 deepshikha_palariya\n",
      "259 throughmyeyes_pragati\n",
      "260 tunes.talks.texts\n",
      "261 shams.gaur\n",
      "262 ashmit_vermaa\n",
      "263 lucy__woodcock\n",
      "264 diamongkingdelhi\n",
      "265 arhaanhayat\n",
      "266 himanshukhanna29\n",
      "267 kawatra.manish\n",
      "268 sanatseth23\n",
      "269 shubhgoyal94\n",
      "270 zaid__khan\n",
      "271 amitoj_sareen\n",
      "272 tarleenkaur05\n",
      "273 instadr_ad\n",
      "274 utkarsh_singh_96\n",
      "275 keshavawasty\n",
      "276 prathamssingh\n",
      "277 vikas.rawat_official\n",
      "278 prabhjyot_singh06\n",
      "279 devanshijangid\n",
      "280 kanpuriya_wala\n",
      "281 aditi_chauhann\n",
      "282 harshiiiis_\n",
      "283 madaan.sumi679\n",
      "284 sreya_vs.112\n",
      "285 bhalla1640\n",
      "286 sada.b4187\n",
      "287 goforneet\n",
      "288 navoditagupta\n",
      "289 mycookbook007\n",
      "290 mohammedshahid9565\n",
      "291 fem_earth\n",
      "292 suhaas_25\n",
      "293 aftabsthetic\n",
      "294 iam_rohansingh14\n",
      "295 akshadaw512\n",
      "296 piyushsm16\n",
      "297 priyanka_sharma1983\n",
      "298 madskulin\n",
      "299 gaurav894\n",
      "300 devanshi_khurana\n",
      "301 cherrytrench\n",
      "302 pandasfood.world\n",
      "303 man__with__plan\n",
      "304 rehan_joshua\n",
      "305 jatinbansal04\n",
      "306 piyushpuri.28\n",
      "307 _bearded.panda_\n",
      "308 ypranoy910\n",
      "309 boliderahul\n",
      "310 bxb.the.builder\n",
      "311 nitairoy.nitairoy.9085\n",
      "312 bruh.for.real.360\n",
      "313 priyankaaniljanyani\n",
      "314 richajoshi0606\n",
      "315 shilpimittal9\n",
      "316 therahul_singh\n",
      "317 amit930525\n",
      "318 swa.ni.kah\n",
      "319 indiaofficials._\n",
      "320 kumar_0198\n",
      "321 anish.malhotra_\n",
      "322 kirti.chadha24\n",
      "323 bintul__islam\n",
      "324 aadi___singh07\n",
      "325 atul_tiwary_\n",
      "326 iamparizazc\n",
      "327 recycle_recreate\n",
      "328 oseen_adhikarii\n",
      "329 seemarajpal9\n",
      "330 mdsalmanijav\n",
      "331 iamjassi_kaur\n",
      "332 agyat_abhi\n",
      "333 himansuu.flicks_\n",
      "334 simranghai_17\n",
      "335 akshionly\n",
      "336 khandujapooja\n",
      "337 parvez0921\n",
      "338 aditi_1802\n",
      "339 neha_negi09\n",
      "340 whimsypeek\n",
      "341 ritik_14_rawat\n",
      "342 groverrachna.savesoil\n",
      "343 glitters_note\n",
      "344 _im_nancy_23\n",
      "345 _parulchoudhary__\n",
      "346 krishnagift.store\n",
      "347 travel__stories20\n",
      "348 istg_aditya\n",
      "349 tfk.thefablekitchen\n",
      "350 devisingh2271\n",
      "351 wk072_baba\n",
      "352 _avi00039\n",
      "353 shivampanday__\n",
      "354 tanyamichelle26\n",
      "355 theaman_97\n",
      "356 priya6drean\n",
      "357 yashavisharma\n",
      "358 samkhush1996\n",
      "359 deepak.reddyl\n",
      "360 randomclick_7\n",
      "361 serialchiller_13\n",
      "362 ayes.hasingh1003\n",
      "363 sakshiagarwal1001\n",
      "364 mannukumar98862023\n",
      "365 aggarwalstuti\n",
      "366 malhotrashivangideepak\n",
      "367 himanshi.aggarwal.0706\n",
      "368 bali_lavanya\n",
      "369 girlyapa_ocean\n",
      "370 sachin.aj2003\n",
      "371 sejal_kapoor.4\n",
      "372 anusha.yadav04\n",
      "373 akshat__anand\n",
      "374 arajdey\n",
      "375 _agarwal_ritik\n",
      "376 kaja.ll2004\n",
      "377 harshitmehrotra17\n",
      "378 blissfulllove008\n",
      "379 mahendramali1975\n",
      "380 rishee_bagdia\n",
      "381 travelwith_chubbymummy\n",
      "382 kalam_se_ghungroo_tak\n",
      "383 kapooranshum\n",
      "384 ch_jatin_singh_2709\n",
      "385 kritikagoyal_kg\n",
      "386 pahadophile\n",
      "387 gosainsoni\n",
      "388 meemansaa_\n",
      "389 abeyyyyyaar\n",
      "390 _navuwu\n",
      "391 anujthakur715\n",
      "392 ria.a09\n",
      "393 rockysingh9432\n",
      "394 jyotipurisethi\n",
      "395 ur_arj_\n",
      "396 neha04nidhi\n",
      "397 archit._.chauhan\n",
      "398 neelesh_lalwani_\n",
      "399 tokaslavish_\n",
      "400 faiz_20020\n",
      "401 nimishaa.razdann\n",
      "402 adakhan_333\n",
      "403 chet.noi\n",
      "404 pujaanand__\n",
      "405 pulkita_05\n",
      "406 dawg_on_meta\n",
      "407 parul_goel9\n",
      "408 sizen19855\n",
      "409 vidhi2757\n",
      "410 vislavath_rajesh11\n",
      "411 teja_nnt\n",
      "412 singer_yadav_chhotu_sangam\n",
      "413 mukul_2109\n",
      "414 milan_kaur_\n",
      "415 surander.attri\n",
      "416 kunal_kushwah_12\n",
      "417 dr.anmolahuja\n",
      "418 shash_khr\n",
      "419 sandeepatkakatiya\n",
      "420 aarfa_zuhaib\n",
      "421 shikhhhhaa\n",
      "422 kunalpreet_singh99\n",
      "423 angeles_daughter\n",
      "424 bun_mask_90\n",
      "425 manmeet176\n",
      "426 butterchicken.jpg\n",
      "427 simranrawat\n",
      "428 avgiguserbelike\n",
      "429 upasanabedi\n",
      "430 socialnovaindia\n",
      "431 kartik__singhal_\n",
      "432 thejugnustore\n",
      "433 sheetalsinghvi\n",
      "434 ananyashree.rathore\n",
      "435 shreejaaaaaaa_._\n",
      "436 siya_kapoor_11\n",
      "437 nitincpt\n",
      "438 samant.manish\n",
      "439 raghavarjhunsharma\n",
      "440 albert__alfred_\n",
      "441 farruuuuuuu_\n",
      "442 akanksha_tomar9\n",
      "443 devangijainn\n",
      "444 dishaptuteja\n",
      "445 itsanshi_11\n",
      "446 ruchiramaheshwari\n",
      "447 syedd.shahh\n",
      "448 shruti._.bajaj\n",
      "449 sahilgoyal376\n",
      "450 marshmallow_dumplings\n",
      "451 jyotikumari2826\n",
      "452 ishu.jain.98\n",
      "453 delhiwoop\n",
      "454 rumjhum_chowdhury\n",
      "455 dewy_eyed_dss\n",
      "456 annuchoudhary358\n",
      "457 abhishek_shukla0011\n",
      "458 soniadhwn\n",
      "459 martynsumit\n",
      "460 shakirsword\n",
      "461 _bestbakes_\n",
      "462 jbrara_1195\n",
      "463 why_ral\n",
      "464 drkumudsharma\n",
      "465 alok0144\n",
      "466 the_intro_vert_guy\n",
      "467 sadiq.siddiquii\n",
      "468 dev_sardana_7\n",
      "469 mehak_hooda_\n",
      "470 allllshadesofdramatic_\n",
      "471 kinggatesecure\n",
      "472 jasperbu123\n",
      "473 harshsonegra326\n",
      "474 asangha._\n",
      "475 iterceptimran\n",
      "476 hardikjain2395\n",
      "477 lushell95\n",
      "478 sameer.___.verma\n",
      "479 enchantersfling\n",
      "480 recipestofitness\n",
      "481 _.swatidixit._\n",
      "482 iffat._fatma\n",
      "483 meriemeladili\n",
      "484 roohimathur107\n",
      "485 a.a.sthapriv\n",
      "486 _.tanishaaaaaaaa\n",
      "487 _singh_anu_24\n",
      "488 vermadivya1903\n",
      "489 aayush_0208\n",
      "490 ayushkhurana24\n",
      "491 vishaal_chauhan__\n",
      "492 tanyahjain\n",
      "493 sad.story115\n",
      "494 f.a.t.i.m.a.a.n.a.m\n",
      "495 docshabby\n",
      "496 khushboosiddhu98\n",
      "497 iam_story_pic\n",
      "498 farhanaz_hoque_12\n",
      "499 aofficial_11\n",
      "500 manyaaaspamms\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(li)):\n",
    "    print(i+1,li[i])\n",
    "# print(len(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d7e22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button()\n",
    "open_search_profile(\"foodtalkindia\")\n",
    "li = extract_follower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb390b65",
   "metadata": {},
   "source": [
    "### Only 50 got extracted as foodtalkindia has restricted upto 50 to be seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d0c4467",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 me_you_anonymous\n",
      "2 i_am_roshan_avhad\n",
      "3 indian_food_blogger_27\n",
      "4 bhatiamansha\n",
      "5 ginsamfood\n",
      "6 wandering.kalakar\n",
      "7 aspirant7732\n",
      "8 x_oma_001_x\n",
      "9 jashn.ag\n",
      "10 enroute2explore\n",
      "11 sumitsingh8592\n",
      "12 bomcity.spy\n",
      "13 kasviscameraroll\n",
      "14 trisha_dhamija\n",
      "15 whatsinthe965\n",
      "16 harshsaini1996\n",
      "17 amanagarwal111\n",
      "18 rahulsinghsail1996\n",
      "19 divyaagarwal74\n",
      "20 krxsskross\n",
      "21 akanksha_sogani\n",
      "22 desi_tadkaa76\n",
      "23 hina6075\n",
      "24 shivamnamkeenbakery2023\n",
      "25 thevineetagrawal\n",
      "26 aravind_bindusaran\n",
      "27 ashniibansal\n",
      "28 manish9837611051\n",
      "29 sameer_rasool3\n",
      "30 mr.saheb111\n",
      "31 surindersha1\n",
      "32 foodienicong\n",
      "33 rupender_singh_100\n",
      "34 rashi_goel____\n",
      "35 live.yourowndream\n",
      "36 sambhajinagarfoodexplorer1\n",
      "37 7725shivam\n",
      "38 sakshimmer\n",
      "39 sophieharlandt\n",
      "40 dipalikamlathakur\n",
      "41 molla.marufhossain\n",
      "42 aya_aya3443\n",
      "43 tejas_joshi30\n",
      "44 palvindersingh__\n",
      "45 http.keshav._\n",
      "46 choloberoi\n",
      "47 mycookbook007\n",
      "48 minam_manikantaswami\n",
      "49 butterchicken.jpg\n",
      "50 notjustacategory\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(li)):\n",
    "    print(i+1,li[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecd008ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def following():\n",
    "    try:\n",
    "        #locating following button and clicking it\n",
    "        following_btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,'//li/a[@class =\"x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz _alvs _a6hd\"]')))\n",
    "        following_btn[1].click()\n",
    "        time.sleep(2)\n",
    "        #locating list of follower in the frame\n",
    "        following_panel_frame = driver.find_element(By.XPATH,'//div[@class = \"_aano\"]')\n",
    "        #scrolling until all the final user\n",
    "        for i in range(150):\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",following_panel_frame)\n",
    "        time.sleep(3)    \n",
    "        name = []\n",
    "        #extracting user data\n",
    "        following = wait.until(EC.presence_of_all_elements_located((By.XPATH,'//span[@class = \"_aacl _aaco _aacw _aacx _aad7 _aade\"]')))\n",
    "        for i in following:\n",
    "            name.append(i.text.split('\\n')[0])\n",
    "        return name    \n",
    "    except TE:\n",
    "        print(\"Something Went Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21365943",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button()\n",
    "time.sleep(3)\n",
    "\n",
    "open_search_profile(\"foodtalkindia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d5e9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = following()\n",
    "# converting the list we got from the above extraction\n",
    "name_list = set(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d48d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_profile():\n",
    "    try:\n",
    "        profile_btn = wait.until(EC.presence_of_element_located((By.LINK_TEXT,'Profile')))\n",
    "        profile_btn.click()\n",
    "    except TE:\n",
    "        print(\"Something Went Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8df550d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_profile() #opening my own profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b253032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name_list = following()\n",
    "\n",
    "my_name_list = set(my_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd864476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such users found\n"
     ]
    }
   ],
   "source": [
    "#taking intersection so new_set contains only the user who followed by me\n",
    "new_set=(name_list).intersection(my_name_list)\n",
    "if len(new_set) == 0:\n",
    "    print('No such users found')\n",
    "else:\n",
    "    #extracting my followers\n",
    "    my_followers = extract_follower()\n",
    "    my_followers = set(my_follower)\n",
    "    #taking intersection with new_set, so new_set2 contains only users that I am following them but they don’t follow me\n",
    "    new_set2=new_set.intersection(my_follower)\n",
    "    if len(new_set2) == 0:\n",
    "        print('No such users found')\n",
    "    else:\n",
    "        for user in new_set2:\n",
    "            print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe2c05d",
   "metadata": {},
   "source": [
    "## PROBLEM - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a1661",
   "metadata": {},
   "source": [
    "Check the story of ‘coding.ninjas’. Consider the following Scenarios and print error messages accordingly -\n",
    "1. If You have already seen the story.\n",
    "2. Or The user has no story.\n",
    "3. Or View the story if not yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0a588ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_story():\n",
    "    try:\n",
    "        #finding story or profile picture \n",
    "        story = wait.until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"_aarf _aarg\"]'))) \n",
    "        size = driver.find_element(By.XPATH,'//div/canvas[\"_aarh\"]').get_attribute('height')\n",
    "        if int(size) == 166:\n",
    "            print(\"Already seen the story\")\n",
    "        else:\n",
    "            print(\"Viewing the story\")\n",
    "            driver.execute_script(\"arguments[0].click();\",story)    \n",
    "    except :\n",
    "        print(\"No Story is available to view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a077a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button()\n",
    "time.sleep(3)\n",
    "open_search_profile('coding.ninjas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "242569bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already seen the story\n"
     ]
    }
   ],
   "source": [
    "check_story()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
